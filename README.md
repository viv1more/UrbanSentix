# ğŸš€ UrbanSentix â€“ Sentiment Analysis on City Services

UrbanSentix is a Big Data-powered sentiment analysis project focused on understanding public opinion about **city services** using real-time and historical data. This project uses scalable, open-source tools and is designed to be **lightweight** and **compatible**.

---

## ğŸ¯ Project Goals & Scope

- **Objective:**  
  Analyze citizen feedback to understand sentiment trends on urban services like water, roads, sanitation, and public safety.

- **Target Outcomes:**  
  - Identify positive and negative public sentiment  
  - Provide real-time insights to authorities  
  - Enable proactive decision-making for urban management  

---

## ğŸ“Š Data Sources

- ğŸ—£ **Citizen Complaints** â€“ Government portals, city websites  
- ğŸŒ **Social Media** â€“ Twitter, Reddit, Facebook  
- ğŸ“° **News Articles** â€“ Local news platforms and city bulletins

---

## ğŸ§° Tech Stack (Windows & Hadoop-Free)

| Layer               | Tool/Tech                | Purpose                                |
|---------------------|--------------------------|----------------------------------------|
| ğŸ” Data Collection   | `Scrapy`                 | Scraping complaints, posts & news      |
| âš™ Data Processing    | `PySpark (Standalone)`   | Scalable data processing               |
| ğŸ§  NLP & Sentiment   | `spaCy`, `TextBlob`      | Text cleaning & sentiment scoring      |
| ğŸ›¢ï¸ Data Storage       | `DuckDB`, `PostgreSQL`    | Lightweight + structured DB storage    |
| ğŸ“ˆ Visualization      | `Apache Superset`, `Power BI` | Dashboards and real-time insights  |
| ğŸ”— API Integration   | `FastAPI`                | Real-time access to sentiment data     |

---

## ğŸ“Œ Key Features

- âœ”ï¸ Multi-source sentiment tracking  
- âœ”ï¸ Dashboard with filtering by date, location, and topic  
- âœ”ï¸ Lightweight, no external Hadoop setup required  
- âœ”ï¸ Real-time API for integration with external apps  

---

## ğŸ“ Folder Structure

UrbanSentix/
â”œâ”€â”€ README.md                      # Project overview
â”œâ”€â”€ LICENSE                        # License file (e.g., MIT)
â”œâ”€â”€ requirements.txt              # Python dependencies

â”œâ”€â”€ data_sources/                 
â”‚   â”œâ”€â”€ raw/                      # Unprocessed scraped data
â”‚   â”œâ”€â”€ processed/                # Cleaned/structured data
â”‚   â””â”€â”€ external/                # CSVs/news articles/social media exports

â”œâ”€â”€ data_scraping/
â”‚   â””â”€â”€ scrapy_spiders/          # Scrapy spiders for complaints, news, social
â”‚       â”œâ”€â”€ complaints_spider.py
â”‚       â”œâ”€â”€ news_spider.py
â”‚       â””â”€â”€ twitter_scraper.py

â”œâ”€â”€ sentiment_analysis/
â”‚   â”œâ”€â”€ text_cleaning.py         # Preprocessing scripts
â”‚   â”œâ”€â”€ sentiment_spacy.py       # spaCy sentiment pipeline
â”‚   â””â”€â”€ sentiment_textblob.py    # TextBlob-based fallback

â”œâ”€â”€ spark_processing/
â”‚   â”œâ”€â”€ spark_job.py             # PySpark transformation scripts
â”‚   â””â”€â”€ config/                  # Spark session config and schema defs

â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ duckdb_init.sql          # DuckDB table setup
â”‚   â”œâ”€â”€ postgresql_schema.sql    # PostgreSQL schema setup
â”‚   â””â”€â”€ db_utils.py              # DB insert/query helpers

â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ powerbi/                 # PBIX files or export images
â”‚   â””â”€â”€ superset/                # Superset dashboard JSONs and configs

â”œâ”€â”€ api/
â”‚   â””â”€â”€ app/                     
â”‚       â”œâ”€â”€ main.py              # FastAPI entry point
â”‚       â”œâ”€â”€ routes/             # API endpoints
â”‚       â””â”€â”€ models/             # Pydantic models and DB models

â”œâ”€â”€ notebooks/                   # Jupyter notebooks for EDA & prototyping
â”‚   â””â”€â”€ exploratory_analysis.ipynb

â””â”€â”€ utils/
    â”œâ”€â”€ helpers.py               # Shared utility functions
    â””â”€â”€ logger.py                # Logging setup
